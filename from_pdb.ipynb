{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Пуся\\AppData\\Local\\Temp\\ipykernel_10352\\845522939.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from typing import List, Set, Dict, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "from biopandas.pdb import PandasPdb\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "import Bio.PDB\n",
    "\n",
    "from Bio.Data.IUPACData import protein_letters_3to1\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph as knn_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.datasets.utils as du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных из PDB-файла "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIG = 'ligand'\n",
    "REC = 'receptor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atom: \n",
    "\n",
    "    def __init__(self, name, coords):\n",
    "        self.name = name \n",
    "        self.x_coord, self.y_coord, self.z_coord = coords\n",
    "        self.element = 'C' if self.name == 'CA' or self.name == 'C'else 'N'\n",
    "\n",
    "    def get_coords(self): \n",
    "        return np.array([self.x_coord, self.y_coord, self.z_coord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chain: \n",
    "\n",
    "    def __init__(self, id, res_name, res_seq):\n",
    "        self.id = id\n",
    "        self.atoms = []\n",
    "        self.res_name = res_name\n",
    "        self.res_seq = res_seq\n",
    "\n",
    "    def add_atom(self, name, coords):\n",
    "        self.atoms.append(Atom(name, coords))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.atoms)\n",
    "    \n",
    "    def get_vectors_of_coords(self):\n",
    "\n",
    "        n_c, ca_c, c_c = 0, 0, 0\n",
    "\n",
    "        for atom in self.atoms:\n",
    "            if atom.name == 'N':\n",
    "                n_c = atom.get_coords()\n",
    "            elif atom.name == 'CA':\n",
    "                ca_c = atom.get_coords()\n",
    "            else: \n",
    "                c_c = atom.get_coords() \n",
    "\n",
    "\n",
    "        u_i = (n_c - ca_c) / np.linalg.norm(n_c - ca_c)\n",
    "        t_i = (c_c - ca_c) / np.linalg.norm(c_c - ca_c)\n",
    "        n_i = np.cross(u_i, t_i) / np.linalg.norm(np.cross(u_i, t_i))\n",
    "        v_i = np.cross(n_i, u_i)\n",
    "\n",
    "        \n",
    "        return n_i, u_i, v_i\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protein: \n",
    "\n",
    "    def __init__(self, type_):\n",
    "        self.chains = []\n",
    "        self.type = type_ \n",
    "        self.edge_index = None\n",
    "        self.n_coords, self.c_coords, self.ca_coords = [], [], []\n",
    "\n",
    "\n",
    "    def add_chain(self, chain: Chain):\n",
    "        self.chains.append(chain)\n",
    "\n",
    "    def get_coords_arrays(self):\n",
    "\n",
    "        for chain in self.chains:\n",
    "            for atom in chain.atoms: \n",
    "                if atom.name == 'CA':\n",
    "                    self.ca_coords.append(atom.get_coords())\n",
    "                elif atom.name == 'C':\n",
    "                    self.c_coords.append(atom.get_coords())\n",
    "                else:\n",
    "                    self.n_coords.append(atom.get_coords())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.n_coords)\n",
    "\n",
    "\n",
    "    def get_vectors_of_coords_arrays(self):\n",
    "\n",
    "        n_i_list, u_i_list, v_i_list = [], [], []\n",
    "\n",
    "        for chain in self.chains:\n",
    "            n_i, u_i, v_i = chain.get_vectors_of_coords()\n",
    "            n_i_list.append(n_i)\n",
    "            u_i_list.append(u_i)\n",
    "            v_i_list.append(v_i)\n",
    "            \n",
    "        return np.stack(n_i_list), np.stack(u_i_list), np.stack(v_i_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tasks:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tasks = []\n",
    "\n",
    "    def add_task(self, paths, type_:str):\n",
    "        self.tasks.append({'pair': paths, 'type': type_})\n",
    "\n",
    "    def get_task(self, idx: int):\n",
    "        if idx < len(self.tasks):\n",
    "            return self.tasks[idx]\n",
    "        else:\n",
    "            raise IndexError('Index out of range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "\n",
    "    def __init__(self, data_file, knn_size=3, split = ',', verbose=False):\n",
    "        self.parser = Bio.PDB.PDBParser()\n",
    "        self.knn_size = knn_size\n",
    "        self.data_to_load = pd.read_csv(data_file, sep=split, header=0)\n",
    "        print(self.data_to_load)\n",
    "        self.verbose = verbose\n",
    "        self.tasks = []\n",
    "\n",
    "    def parse_pdb(self, file_path, type_) -> Protein:\n",
    "\n",
    "        structure = self.parser.get_structure(file_path, file_path)\n",
    "        protein = Protein(type_)\n",
    "        \n",
    "        for model in structure:\n",
    "            for one_chain in model:\n",
    "                for part in one_chain.get_residues():\n",
    "\n",
    "                    chain = Chain(\n",
    "                        id=repr(one_chain).replace(\"<Chain id=\", \"\").replace(\">\", \"\"), \n",
    "                        res_name=part.get_resname(), \n",
    "                        res_seq=str(part).split(' ')[4].split('=')[1])\n",
    "                    \n",
    "                    for atom in part: \n",
    "                        if atom.get_name() in ['C', 'CA', 'N']:\n",
    "                            chain.add_atom(atom.get_name(), atom.get_coord())\n",
    "                            \n",
    "                    if len(chain) != 0:\n",
    "                        protein.add_chain(chain)\n",
    "            \n",
    "        return protein\n",
    "\n",
    "    def read_data(self) -> Tasks:\n",
    "        tasks = Tasks()\n",
    "        for id, line in self.data_to_load.iterrows():\n",
    "            path_to_rec = './structures/' + line['path'] + '_r_b.pdb'\n",
    "            path_to_lig = './structures/' + line['path']  + '_l_b.pdb'\n",
    "            tasks.add_task((path_to_lig, path_to_rec), line['split'])\n",
    "        self.tasks = tasks\n",
    "        return tasks\n",
    "    \n",
    "    def process_data(self, indexes) -> List:\n",
    "        train_pairs = []\n",
    "        test_pairs = []\n",
    "        val_pairs = []\n",
    "        \n",
    "        for idx in indexes: \n",
    "            paths, type_ = self.tasks.get_task(idx).values()\n",
    "\n",
    "            ligand = self.parse_pdb(paths[0], LIG)\n",
    "            receptor = self.parse_pdb(paths[1], REC)\n",
    "\n",
    "            ligand.get_coords_arrays()\n",
    "            receptor.get_coords_arrays()\n",
    "\n",
    "            edge_index = knn_graph(np.vstack((ligand.c_coords, ligand.ca_coords, ligand.n_coords)), self.knn_size)\n",
    "            ligand.edge_index = edge_index\n",
    "\n",
    "            edge_index = knn_graph(np.vstack((receptor.c_coords, receptor.ca_coords, receptor.n_coords)), self.knn_size)\n",
    "            receptor.edge_index = edge_index\n",
    "\n",
    "            if type_ == 'test':\n",
    "                test_pairs.append((ligand, receptor))\n",
    "            elif type_ == 'train':\n",
    "                train_pairs.append((ligand, receptor))\n",
    "            else:\n",
    "                val_pairs.append((ligand, receptor))\n",
    "        \n",
    "\n",
    "        return test_pairs, train_pairs, val_pairs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   path split\n",
      "0  1A2K  test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 497)\t1.0\n",
      "  (0, 248)\t1.0\n",
      "  (0, 249)\t1.0\n",
      "  (1, 498)\t1.0\n",
      "  (1, 249)\t1.0\n",
      "  (1, 250)\t1.0\n",
      "  (2, 499)\t1.0\n",
      "  (2, 250)\t1.0\n",
      "  (2, 251)\t1.0\n",
      "  (3, 500)\t1.0\n",
      "  (3, 251)\t1.0\n",
      "  (3, 252)\t1.0\n",
      "  (4, 501)\t1.0\n",
      "  (4, 252)\t1.0\n",
      "  (4, 253)\t1.0\n",
      "  (5, 502)\t1.0\n",
      "  (5, 253)\t1.0\n",
      "  (5, 254)\t1.0\n",
      "  (6, 503)\t1.0\n",
      "  (6, 254)\t1.0\n",
      "  (6, 502)\t1.0\n",
      "  (7, 504)\t1.0\n",
      "  (7, 255)\t1.0\n",
      "  (7, 503)\t1.0\n",
      "  (8, 505)\t1.0\n",
      "  :\t:\n",
      "  (735, 486)\t1.0\n",
      "  (736, 239)\t1.0\n",
      "  (736, 488)\t1.0\n",
      "  (736, 487)\t1.0\n",
      "  (737, 240)\t1.0\n",
      "  (737, 489)\t1.0\n",
      "  (737, 241)\t1.0\n",
      "  (738, 241)\t1.0\n",
      "  (738, 490)\t1.0\n",
      "  (738, 489)\t1.0\n",
      "  (739, 242)\t1.0\n",
      "  (739, 491)\t1.0\n",
      "  (739, 243)\t1.0\n",
      "  (740, 243)\t1.0\n",
      "  (740, 492)\t1.0\n",
      "  (740, 491)\t1.0\n",
      "  (741, 244)\t1.0\n",
      "  (741, 493)\t1.0\n",
      "  (741, 492)\t1.0\n",
      "  (742, 245)\t1.0\n",
      "  (742, 494)\t1.0\n",
      "  (742, 246)\t1.0\n",
      "  (743, 246)\t1.0\n",
      "  (743, 495)\t1.0\n",
      "  (743, 494)\t1.0\n"
     ]
    }
   ],
   "source": [
    "loader = Loader('./splits_test.csv')\n",
    "loader.read_data()\n",
    "loader.process_data([0])\n",
    "\n",
    "test_pairs, train_pairs, val_pairs = loader.process_data([0])\n",
    "one_task = test_pairs[0]\n",
    "print(one_task[1].edge_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
